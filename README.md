# FastAPI Template

A production-grade FastAPI template for building scalable, maintainable, and testable applications with built-in fallback mechanisms.

## Features

- ğŸš€ **Production-Ready**: Built with scalability and maintainability in mind
- ğŸ§ª **TDD-First**: Comprehensive testing setup with pytest
- ğŸ”„ **Multi-Environment**: Support for dev, UAT, and production environments
- ğŸ“Š **Observability**: Built-in metrics, tracing, and logging
- ğŸ”’ **Security**: JWT authentication and role-based access control
- ğŸ—„ï¸ **Database**: SQLAlchemy + Alembic with automatic SQLite fallback
- ğŸ”„ **Caching**: Redis integration with in-memory fallback
- ğŸš¦ **Task Queue**: Celery with in-memory fallback
- ğŸ“ **Documentation**: Auto-generated OpenAPI docs
- ğŸ³ **Containerized**: Docker and docker-compose support
- ğŸ”„ **CI/CD**: GitHub Actions pipeline
- ğŸ›¡ï¸ **Resilience**: Automatic fallback mechanisms for all critical services
- ğŸ“ˆ **Monitoring**: Prometheus + Grafana integration

## Project Structure

```
fastapi-template/
â”œâ”€â”€ app/                       # Application code
â”‚   â”œâ”€â”€ main.py                # ASGI entrypoint
â”‚   â”œâ”€â”€ core/                  # Core functionality
â”‚   â”‚   â”œâ”€â”€ settings.py        # Pydantic Settings (env)
â”‚   â”‚   â”œâ”€â”€ logging.py         # Structured logging setup
â”‚   â”‚   â”œâ”€â”€ security.py        # JWT, OAuth2 schemes, CORS
â”‚   â”‚   â”œâ”€â”€ cache.py           # Redis cache with fallback
â”‚   â”‚   â”œâ”€â”€ tasks.py           # Celery tasks with fallback
â”‚   â”‚   â””â”€â”€ events.py          # Startup/shutdown handlers
â”‚   â”œâ”€â”€ db/                    # Database layer
â”‚   â”‚   â”œâ”€â”€ base.py            # Base model class (declarative)
â”‚   â”‚   â”œâ”€â”€ session.py         # SessionLocal, engine, fallback logic
â”‚   â”‚   â””â”€â”€ migrations/        # Alembic env and versions
â”‚   â”œâ”€â”€ domains/               # Domain-driven subpackages
â”‚   â”‚   â”œâ”€â”€ users/             # User domain package
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py      # APIRouter for /users  
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py     # Pydantic models for requests/responses
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py      # SQLAlchemy definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py     # Business logic  
â”‚   â”‚   â”‚   â”œâ”€â”€ repository.py  # DB access abstraction  
â”‚   â”‚   â”‚   â””â”€â”€ dependencies.py # fastapi.Depends helpers
â”‚   â”‚   â””â”€â”€ health/            # Health check domain
â”‚   â”œâ”€â”€ api/                   # Global API setup
â”‚   â”‚   â”œâ”€â”€ deps.py            # Common dependencies  
â”‚   â”‚   â””â”€â”€ router.py          # Main router including all domains
â”‚   â”œâ”€â”€ middleware/            # Custom middlewares                      
â”‚   â”œâ”€â”€ tasks/                 # Background tasks with Celery 
â”‚   â””â”€â”€ utils/                 # Shared utilities, e.g. pagination
â”œâ”€â”€ tests/                     # Test suite mirroring app structure
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ alembic/                   # Database migrations
â”œâ”€â”€ prometheus.yml             # Prometheus configuration
â””â”€â”€ docker-compose.yml         # Service orchestration
```

## Quick Start

1. Clone the repository:
```bash
git clone https://github.com/yourusername/fastapi-template.git
cd fastapi-template
```

2. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

3. Start the development environment:
```bash
docker-compose up -d
```

4. Run migrations:
```bash
docker-compose exec app alembic upgrade head
```

5. Access the services:
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Metrics: http://localhost:8000/metrics
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000
- Flower (Celery): http://localhost:5555

## Development

### Running Tests
```bash
docker-compose exec app pytest
```

### Code Quality
```bash
docker-compose exec app black .
docker-compose exec app isort .
docker-compose exec app flake8
```

### Running the Application Locally
If you prefer to run the application without Docker:

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your local configuration
```

3. Run the application:
```bash
python run.py
```

The application will automatically:
- Try to connect to PostgreSQL, fall back to SQLite if unavailable
- Use Redis for caching, fall back to in-memory cache if unavailable
- Use Celery for task queue, fall back to in-memory queue if unavailable

### Database Migrations
```bash
# Create a new migration
docker-compose exec app alembic revision --autogenerate -m "description"

# Apply migrations
docker-compose exec app alembic upgrade head
```

### Fallback Mechanisms

The application includes automatic fallback mechanisms for critical services:

1. **Database Fallback**:
   - Primary: PostgreSQL
   - Fallback: SQLite
   - Configure with `DB_FALLBACK=true` in `.env`

2. **Cache Fallback**:
   - Primary: Redis
   - Fallback: In-memory cache
   - Configure with `REDIS_FALLBACK=true` in `.env`

3. **Task Queue Fallback**:
   - Primary: Celery
   - Fallback: In-memory queue
   - Configure with `CELERY_FALLBACK=true` in `.env`

### Monitoring

The application includes comprehensive monitoring:

1. **Prometheus Metrics**:
   - Application metrics at `/metrics`
   - Service health checks
   - Custom business metrics

2. **Grafana Dashboards**:
   - Pre-configured dashboards
   - Service health monitoring
   - Performance metrics

3. **Logging**:
   - JSON-formatted logs
   - Structured logging with context
   - Log levels configurable via environment

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

MIT License - see LICENSE file for details